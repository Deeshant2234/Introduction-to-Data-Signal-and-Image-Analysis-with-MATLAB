function [class,score] = my_predictpca(mdl,data)
% Initialize output 'class' and 'score' to Mx1 zero vectors
[r,c]=size(data);
class=zeros(r,1);
score=zeros(r,1);
% Loop over the M samples, to classify each 'i'th sample
%% In a nested loop, loop over each 'j'th class to compare the 'i'th sample to the 'j'th class.
%% The minimium Mahalanobis distance across the class pca models is used to choose our classification for the 'i'th sample
%% The classification and the Mahalanobis distance are storedâ€¦end


% embed your MahalanobisDistance function you created in the previous assignment here:
function [md,b,std_per_mode] = MahalanobisDistance(pcamdl,v)
b=pcamdl.eigvects*(v-pcamdl.mu)';
std_per_mode=abs(b)./sqrt(pcamdl.eigvals);
md=sqrt(sum(std_per_mode.^2));
end

-------------------Calling our Funcrion---------------------------------------

load fisheriris
[~,~,class] = unique(species);
%split into 50/50 training and testing data
D_train = meas(1:2:end,:);
class_train = class(1:2:end);
D_test = meas(2:2:end,:);
class_test = class(2:2:end);

% Create pca model struct with pca model for each class using the training set (this is what 'my_fitpca' would do)
for i=1:3
    [eigvects,~,eigvals,~,~,mu] = pca(D_train(class_train==i,:));
    mdl.class(i).eigvects = eigvects; mdl.class(i).eigvals = eigvals; mdl.class(i).mu = mu;
end

% Use our new function to estimate classification on the testing set
[class_est, score_est] = my_predictpca(mdl,D_test);
sum(class_est==class_test)/length(class_est)*100 % We should find 97.3333% classification accuracy!
